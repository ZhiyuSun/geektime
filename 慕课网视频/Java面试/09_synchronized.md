# synchronized

## synchronized

线程安全问题的主要诱因
- 存在共享数据（也称临界资源）
- 存在多条线程共同操作这些共享数据

解决问题的根本方法：
同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作

互斥锁的特性
- 互斥性：即在同一时间只允许一个线程持有某个对象锁，通过这种特性来实现多线程的协调机制，这样在同一时间只有一个线程对需要同步的代码块（复合操作）进行访问。互斥性也称为操作的原子性
- 可见性：必须确保在锁被释放之前，对共享变量所做的修改，对于随后获得该锁的另一个线程是可见的（即在获得锁时应获得最新共享变量的值），否则另一个线程可能是在本地缓存的某个副本上继续操作，从而引起不一致
- synchronized锁的不是代码，锁的都是对象

根据获取锁的分类：获取对象锁和获取类锁
获取对象锁的两种用法
- 同步代码块（synchronized(this)，synchronized(类实例对象)），锁是小括号（）中的实例对象
- 同步非静态方法（synchronized method）,锁是当前对象的实例方法
获取类锁的两种用法
- 同步代码块（synchronize(类.class)），锁是小括号()中的类对象（class对象）、
- 同步静态方法（synchronized static method），锁是当前对象的类对象（Class对象）

## synchronized底层实现原理

实现synchronized的基础
- Java对象头
- Monitor

对象在内存中的布局
- 对象头
- 示例数据
- 对齐填充

对象头的结构：
- mark word 默认存储对象的hashcode，分代年龄，锁类型，锁标志位等信息
- class metadata address 类型指针指向对象的类元数据，jvm通过这个指针确定该对象是哪个类的数据

Monitor:每个Java对象天生自带了看不见的锁

自旋锁与自适应自旋锁

锁消除

锁粗化

synchronized的四种状态：
无锁——偏向锁——轻量级锁——重量级锁

偏向锁：减少同一线程获取锁的代价

锁的内存语义：
- 当线程释放锁时，java内存模型会把该线程对应的本地内存中的共享变量刷新到主内存中
- 而当线程获取到锁时，java内存模型会把该线程所对应的本地内存置为无效，从而使得被监视器保护的临界区代码必须从主内存中读取共享变量

## happens-before

java内存模型JMM
- java内存模型本身是一种抽象的概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式

JMM中的主内存
- 存储Java实例对象
- 包括成员变量、类信息、常量、静态变量等
- 属于数据共享的区域，多线程并发操作时会引发线程安全问题

工作内存
- 存储当前方法的所有本地变量信息，本地变量对其他线程不可见
- 字节码行号指示器、native方法信息
- 属于线程私有数据区域，不存在线程安全问题

JMM与Java内存区域划分是不同的概念层次
- JMM描述的是一组规则，围绕原子性，有序性，可见性展开
- 相似点：存在共享区域和私有区域

主内存与工作内存的数据存储类型以及操作方式归纳
- 方法里的基本数据类型本地变量将直接存储在工作内存的栈帧结构中
- 引用类型的本地变量：引用存储在工作内存中，实例存储在主内存中
- 成员变量，static变量，类信息均会被存储在主内存中
- 主内存共享的方式是线程各拷贝一份数据导工作内存，操作完成后刷新回主内存

A操作的结果需要对B操作可见，则A与B存在happends-before关系

## volitle

volatile：JVM提供的轻量级同步机制

- 保证被volatile修饰的共享变量对所有线程总是可见的
- 禁止指令的重排序优化

volatile变量为何立即可见？
- 当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量值刷新到主内存中
- 当读取一个volatile变量时，JMM会把该线程对于的工作内存置为无效。

volatile如何禁止重排优化
内存屏障（Memory Barrier）
- 保证特定操作的执行顺序
- 保证某些变量的内存可见性

通过插入内存屏障指令禁止在内存凭证前后的指令执行重排序优化
强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本

volatile和synchronized区别
- volatile本质是在告诉JVM当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住直到该线程完成变量操作为止。
- volatile仅能使用在变量级别；synchronized则可以使用在变量、方法和类级别
- volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量修改的可见性和原子性
- volatile不会造成线程的阻塞，synchronized可能会造成线程的阻塞
- volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化

## CAS（compare and swap）

一种高效实现线程安全性的方法
- 支持原子更新操作，适用于计数器，序列发生器等场景
- 属于乐观锁机制，号称lock-free
- CAS操作失败时由开发者决定是继续尝试，还是执行别的操作

### CAS思想

- 包含三个操作数——内存位置，预期原值和新值

缺点：
- 若循环时间长，则开销很大
- 只能保证一个共享变量的原子操作
- ABA问题。解决：AtomicStampedReference

## Java线程池

利用Executors创建不同的线程池满足不同场景的需求

- newFixedThreadPool(int n) 指定工作线程数量的线程池
- newCachedThreadPool() 处理大量短时间工作任务的线程池
- newSingleThreadExector

fork/join框架

为什么要使用线程池
- 降低资源消耗
- 提高线程的可管理性

JUC的三个Executor接口
- Executor：运行新任务的简单接口，将任务提交和任务执行细节解耦
- ExecutorService:具备管理执行器和任务生命周期的方法，提交任务机制更完善
- ScheduledExecutorService:支持Future和定期执行任务

ThreadPoolExecutor:
- corePoolSize:核心线程数量
- maximumPoolSize：线程不够用时能够创建的最大线程数
- workQueue:任务等待队列
- keepAliveTime:抢占的顺序不一定，看运气
- threadFactory:创建新线程
- handler:线程池的饱和策略
    - 不同的策略，可定制

新任务提交execute执行后的判断
- 如果运行的线程少于corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的。
- 如果线程池中的线程数量大于等于corePoolSize且小于maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务
- 如果设置的corePoolSize和maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理
- 如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务

线程池大小如何选定
CPU密集型：线程数=按照核数或者核数+1设定
IO密集型：线程数=cpu核数*(1+平均等待时间/平均工作时间)

