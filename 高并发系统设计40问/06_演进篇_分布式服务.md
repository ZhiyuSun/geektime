# 演进篇_分布式服务

## 21 | 系统架构：每秒1万次请求的系统要做服务化拆分吗？

### 一体化架构的痛点

在技术层面上，数据库连接数可能成为系统的瓶颈。

一体化架构增加了研发的成本抑制了研发效率的提升

最后，一体化架构对于系统的运维也会有很大的影响。

### 如何使用微服务化解决这些痛点

其实可以把与用户相关的逻辑部署成一个单独的服务，其它无论是用户池、内容池还是互动池都连接这个服务来获取和更改用户信息，也就是说只有这个服务可以连接用户库，其它的业务池都不直连用户库获取数据。

我们可以将与业务无关的公用服务抽取出来，下沉成单独的服务。

### 课程小结

从中你应该有所感悟：在架构演进的初期和中期，性能、可用性、可扩展性是我们追求的主要目标，高性能和高可用给用户带来更好的使用体验，扩展性可以方便我们支撑更大量级的并发。但是当系统做的越来越大，团队成员越来越多，我们就不得不考虑成本了。

这里面的“成本”有着复杂的含义，它不仅代表购买服务器的费用，还包括研发团队，内部的开发成本，沟通成本以及运维成本等等，甚至有些时候，成本会成为架构设计中的决定性因素。

## 22 | 微服务架构：微服务化后系统架构要如何改造？

### 微服务拆分的原则

原则一，做到单一服务内部功能的高内聚和低耦合
原则二，你需要关注服务拆分的粒度，先粗略拆分再逐渐细化。
原则三，拆分的过程，要尽量避免影响产品的日常功能迭代。
原则四，服务接口的定义要具备可扩展性。

### 微服务化带来的问题和解决思路

1. 服务接口的调用不再是同一进程内的方法调用而是跨进程的网络调用，这会增加接口响应时间的增加。
2. 多个服务之间有着错综复杂的依赖关系。
3. 服务拆分到多个进程后，一条请求的调用链路上涉及多个服务，那么一旦这个请求的响应时间增长或者是出现错误，我们就很难知道是哪一个服务出现的问题。

## 23 | RPC框架：10万QPS下如何实现毫秒级的服务调用？

### 你所知道的 RPC

说到 RPC（Remote Procedure Call，远程过程调用），你不会陌生，它指的是通过网络调用另一台计算机上部署服务的技术

而 RPC 框架就封装了网络调用的细节，让你像调用本地服务一样调用远程部署的服务。你也许觉得只有像 Dubbo、Grpc、Thrift 这些新兴的框架才算是 RPC 框架，其实严格来说，你很早之前就接触到与 RPC 相关的技术了。

RPC 并不是互联网时代的产物，也不是服务化之后才衍生出来的技术，而是一种规范，只要是封装了网络调用的细节能够实现远程调用其他服务，就可以算作是一种 RPC 技术了。

那么我们要如何优化 RPC 的性能，从而尽量减少网络调用对于性能的影响呢？在这里，你首先需要了解一次 RPC 的调用都经过了哪些步骤，因为这样你才可以针对这些步骤中可能存在的性能瓶颈点提出优化方案。步骤如下：

- 在一次 RPC 调用过程中，客户端首先会将调用的类名、方法名、参数名、参数值等信息，序列化成二进制流；
- 然后客户端将二进制流通过网络发送给服务端；
- 服务端接收到二进制流之后将它反序列化，得到需要调用的类名、方法名、参数名和参数值，再通过动态代理的方式调用对应的方法得到返回值；
- 服务端将返回值序列化，再通过网络发送给客户端；
- 客户端对结果反序列化之后，就可以得到调用的结果了。

### 如何提升网络传输性能

我们常见的五种 I/O 模型：同步阻塞 I/O；同步非阻塞 I/O；同步多路 I/O 复用；信号驱动 I/O；异步 I/O

这五种 I/O 模型中最被广泛使用的是多路 I/O 复用，Linux 系统中的 select、epoll 等系统调用都是支持多路 I/O 复用模型的，Java 中的高性能网络框架 Netty 默认也是使用这种模型。你可以选择它。

选择好了一种高性能的 I/O 模型，是不是就能实现数据在网络上的高效传输呢？其实并没有那么简单，网络性能的调优涉及很多方面，其中不可忽视的一项就是网络参数的调优，接下来我带你了解其中一个典型例子。

### 选择合适的序列化方式

在对网络数据传输完成调优之后，另外一个需要关注的点就是数据的序列化和反序列化。通常所说的序列化是将传输对象转换成二进制串的过程，而反序列化则是相反的动作，是将二进制串转换成对象的过程。

### 课程小结

为了优化 RPC 框架的性能，本节课我带你了解了网络 I/O 模型和序列化方式的选择，它们是实现高并发 RPC 框架的要素，总结起来有三个要点：

- 选择高性能的 I/O 模型，这里我推荐使用同步多路 I/O 复用模型；
- 调试网络参数，这里面有一些经验值的推荐。比如将 tcp_nodelay 设置为 true，也有一些参数需要在运行中来调试，比如接受缓冲区和发送缓冲区的大小，客户端连接请求缓冲队列的大小（back log）等等；
- 序列化协议依据具体业务来选择。如果对性能要求不高可以选择 JSON，否则可以从 Thrift 和 Protobuf 中选择其一。

### 评论区

http是基于TCP又包了一层，主要面向的是web；RPC的一般实现是直接基于TCP，比起HTTP效率更高, 因为传输的数据量更少，比如HTTP会有一大堆用不到的header，且是文本传输，而RPC可以直接传输二进制数据流。

我理解是 rpc（Remote Procedure Call Protocol）远程过程调用协议， http也能实现远程调用，http只不过是rpc的其中一种实现方式，除了http还可以使用 socket 、rmi 只要能实现 远程过程调用 是rpc。至于调用方便的说法，只要通过合理的代码封装都可以实现像调用本地方法一样调用远程服务

一方面调用方便，rpc可以让你像调用本地方法一样调用远程服务，如obj.foo()。
另一方面，rpc传输数据一般基于二进制，是结构化数据，数据占用空间小，传输快，读取数据也快，但没有可读性。http是在tcp的基础上实现的纯文本协议，可读性好但数据占用相对大，还要解析文本，所以性能相对差。

## 24 | 注册中心：分布式系统如何寻址？

### 服务状态管理如何来做

你的 RPC 服务要打开一个端口，然后由注册中心每隔一段时间（比如 30 秒）探测这些端口是否可用，如果可用就认为服务仍然是正常的，否则就可以认为服务不可用，那么注册中心就可以把服务从列表里面删除了。

因此，我们后面把它改造成了心跳模式

其实，服务的注册和发现归根结底是服务治理中的一环，服务治理（service governance），其实更直白的翻译应该是服务的管理，也就是解决多个服务节点组成集群的时候产生的一些复杂的问题。为了帮助你理解，我来做个简单的比喻。
你可以把集群看作是一个微型的城市，把道路看作是组成集群的服务，把行走在道路上的车看作是流量，那么服务治理就是对于整个城市道路的管理。
如果你新建了一条街道（相当于启动了一个新的服务节点），那么就要通知所有的车辆（流量）有新的道路可以走了；你关闭了一条街道，你也要通知所有车辆不要从这条路走了，这就是服务的注册和发现。
我们在道路上安装监控，监视每条道路的流量情况，这就是服务的监控。
道路一旦出现拥堵或者道路需要维修，那么就需要暂时封闭这条道路，由城市来统一调度车辆，走不堵的道路，这就是熔断以及引流。
道路之间纵横交错四通八达，一旦在某条道路上出现拥堵，但是又发现这条道路从头堵到尾，说明事故并不是发生在这条道路上，那么就需要从整体链路上来排查事故究竟处在哪个位置，这就是分布式追踪。
不同道路上的车辆有多有少，那么就需要有一个警察来疏导，在某一个时间走哪一条路会比较快，这就是负载均衡。

## 25 | 分布式Trace：横跨几十个分布式组件的慢请求要如何排查？

### 一体化架构中的慢请求排查如何做

其实，从我的经验出发来说，一个接口响应时间慢，一般是出在跨网络的调用上，比如说请求数据库、缓存或者依赖的第三方服务。所以，我们只需要针对这些调用的客户端类做切面编程，通过插入一些代码打印它们的耗时就好了。

一般来说，切面编程的实现分为两类：
- 一类是静态代理，典型的代表是 AspectJ，它的特点是在编译期做切面代码注入；
- 另一类是动态代理，典型的代表是 Spring AOP，它的特点是在运行期做切面代码注入。

我们做切面的原因，是想生成一些调试的日志，所以我们希望尽量减少对于原先接口性能的影响。因此，我推荐采用静态代理的方式，实现切面编程。

### 如何来做分布式 Trace

因此，我们采用 traceId + spanId 这两个数据维度来记录服务之间的调用关系（这里 traceId 就是 requestId），也就是使用 traceId 串起单次请求，用 spanId 记录每一次 RPC 调用。说起来可能比较抽象，我给你举一个具体的例子。

## 26 | 负载均衡：怎样提升系统的横向扩展能力？

### 负载均衡服务器的种类

负载均衡的含义是：将负载（访问的请求）“均衡”地分配到多个处理节点上。这样可以减少单个处理节点的请求量，提升整体系统的性能。

而在我看来，负载均衡服务大体上可以分为两大类：一类是代理类的负载均衡服务；另一类是客户端负载均衡服务。

所以，我们会使用另一类的负载均衡服务，客户端负载均衡服务，也就是把负载均衡的服务内嵌在 RPC 客户端中。

它一般和客户端应用部署在一个进程中，提供多种选择节点的策略，最终为客户端应用提供一个最佳的、可用的服务端节点。这类服务一般会结合注册中心来使用，注册中心提供服务节点的完整列表，客户端拿到列表之后使用负载均衡服务的策略选取一个合适的节点，然后将请求发到这个节点上。

### 常见的负载均衡策略有哪些

负载均衡策略从大体上来看可以分为两类：

- 一类是静态策略，也就是说负载均衡服务器在选择服务节点时，不会参考后端服务的实际运行的状态；
- 一类是动态策略，也就是说负载均衡服务器会依据后端服务的一些负载特性，来决定要选择哪一个服务节点。

常见的静态策略有几种，其中使用最广泛的是轮询的策略（RoundRobin，RR），这种策略会记录上次请求后端服务的地址或者序号，然后在请求时按照服务列表的顺序，请求下一个后端服务节点。

这些策略的思考点是从调用方的角度出发，选择负载最小、资源最空闲的服务来调用，以期望能得到更高的服务调用性能，也就能最大化地使用服务器的空闲资源，请求也会响应得更迅速。所以我建议你，在实际开发中，优先考虑使用动态的策略。

## 27 | API网关：系统的门面要如何做呢？

### API 网关起到的作用

API 网关（API Gateway）不是一个开源组件，而是一种架构模式，它是将一些服务共有的功能整合在一起，独立部署为单独的一层，用来解决一些服务治理的问题。你可以把它看作系统的边界，它可以对出入系统的流量做统一的管控。

在我看来，API 网关可以分为两类：一类叫做入口网关，一类叫做出口网关。

### API 网关要如何实现

### 如何在你的系统中引入 API 网关

一方面是对服务层接口数据的聚合。比如，商品详情页的接口可能会聚合服务层中，获取商品信息、用户信息、店铺信息以及用户评论等多个服务接口的数据；

另一方面 Web 层还需要将 HTTP 请求转换为 RPC 请求，并且对前端的流量做一些限制，对于某些请求添加设备 ID 的黑名单等等。

因此，我们在做改造的时候，可以先将 API 网关从 Web 层中独立出来，将协议转换、限流、黑白名单等事情挪到 API 网关中来处理，形成独立的入口网关层；

## 28 | 多机房部署：跨地域的分布式系统如何做？

## 29 | Service Mesh：如何屏蔽服务化系统的服务治理细节？